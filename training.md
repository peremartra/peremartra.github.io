---
layout: page
title: Training Programs
permalink: /training/
---

I work with select ML engineering teams on optimization challenges and research partnerships. **Limited to 1-2 concurrent engagements** to ensure deep focus and customized support.

---

## LLM Optimization Program

Hands-on technical training for engineering teams working with large language models in production.

### Topics Covered

**Structured Pruning & Compression**
- Width and depth pruning techniques
- GLU expansion optimization
- Attention mechanism efficiency

**Fairness-Aware Optimization**
- Bias detection and measurement
- Mitigation strategies that preserve performance
- Evaluation frameworks (BBQ, EsBBQ, demographic parity metrics)

**Production Deployment**
- Model quantization strategies
- Inference optimization
- Resource-constrained deployment
- Cost-performance tradeoffs

### Format
- **4 live technical sessions per month** (2 hours each)
- **Async Q&A support** via Slack/email
- **Custom materials** tailored to your team's stack and challenges
- **Hands-on implementation guidance**

### Investment
**€1,800/month per team**

### Ideal For
- ML teams deploying LLMs in production
- Organizations optimizing inference costs
- Teams requiring fairness/bias auditing
- Companies building on-premise LLM solutions

---

## Research Partnership: Agent Migration Framework

**[RESEARCH COLLABORATION - LIMITED AVAILABILITY]**

I'm developing a comprehensive framework for migrating agentic systems from proprietary models (GPT-4, Claude) to open-source alternatives (Llama, Mistral, Qwen). This work will be published as the capstone of my upcoming Manning book.

### What You Get

- **Collaborative framework development** - Work directly with me to solve your migration challenges
- **Migration strategy & implementation guidance** - From benchmarking to production rollout
- **Evaluation methodology** - Frameworks for comparing proprietary vs. OSS agent performance
- **Published case study** - Co-authorship consideration on anonymized learnings

### What I Need

- **Real production challenges** - Access to your agent architecture and migration constraints
- **Performance data** - Benchmark results and production metrics (can be anonymized)
- **Feedback loop** - Active collaboration on framework effectiveness
- **Publication rights** - Permission to publish anonymized learnings and techniques

### Format
- **2 deep-dive sessions per month** (2-3 hours each)
- **Async collaboration** on implementation and testing
- **Shared documentation** and benchmark results
- **Duration**: 3-6 months

### Investment
**€800/month** (subsidized research rate)

### Ideal For
- Teams running production agents on GPT-4/Claude
- Organizations looking to reduce API costs
- Companies requiring data sovereignty / on-premise inference
- Early adopters willing to collaborate on emerging frameworks

---

## Application Process

Due to limited availability, I work with teams through a qualification process:

1. **Initial inquiry** - Brief description of your challenge and team context
2. **Qualification call** - 30-minute discussion to ensure good fit (no cost)
3. **Kickoff** - First session scheduled within 2 weeks

---

## Frequently Asked Questions

**Can we start with a single month?**  
Yes. Programs are month-to-month with 30-day notice for changes.

**Do you work with individual engineers?**  
Currently focused on team engagements (3+ engineers). For individual mentoring, please inquire.

**What if our challenge doesn't fit either program?**  
Let's talk. I occasionally take on custom engagements for unique optimization challenges.

**Can we get references?**  
Yes. I can connect you with teams I've worked with (with their permission).

---

[← Research & Writing](/research) | [Get in Touch →](/contact)
